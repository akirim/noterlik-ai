#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import json
from datetime import datetime
from collections import defaultdict

class SafeDataMerger:
    def __init__(self):
        self.backup_dir = "backup_" + datetime.now().strftime("%Y%m%d_%H%M%S")
        self.all_documents = {}
        self.all_categories = defaultdict(list)
        self.metadata = {
            "version": "2.0",
            "created": datetime.now().isoformat(),
            "total_documents": 0,
            "total_categories": 0,
            "data_sources": []
        }
    
    def create_backup(self):
        """TÃ¼m mevcut dosyalarÄ± yedekle"""
        print("ğŸ›¡ï¸ GÃ¼venlik yedeÄŸi oluÅŸturuluyor...")
        os.makedirs(self.backup_dir, exist_ok=True)
        
        # JSON dosyalarÄ±nÄ± yedekle
        json_files = [
            'modern_data_complete.json',
            'complete_analysis.json', 
            'modern_data.json',
            'noter_genelgeleri.json',
            'fihrist_analysis.json',
            'working_links.json',
            'full_analysis.json'
        ]
        
        for file in json_files:
            if os.path.exists(file):
                import shutil
                shutil.copy2(file, f"{self.backup_dir}/{file}")
                print(f"   âœ… {file} yedeklendi")
        
        # HTML klasÃ¶rÃ¼nÃ¼ yedekle
        if os.path.exists('html'):
            import shutil
            shutil.copytree('html', f"{self.backup_dir}/html")
            print(f"   âœ… html/ klasÃ¶rÃ¼ yedeklendi")
        
        print(f"âœ… Yedek oluÅŸturuldu: {self.backup_dir}")
    
    def analyze_html_files(self):
        """HTML dosyalarÄ±nÄ± analiz et"""
        print("ğŸ“ HTML dosyalarÄ± analiz ediliyor...")
        
        html_dir = 'html'
        if not os.path.exists(html_dir):
            print("âŒ HTML klasÃ¶rÃ¼ bulunamadÄ±!")
            return []
        
        html_files = [f for f in os.listdir(html_dir) if f.endswith('.html')]
        print(f"   ğŸ“„ {len(html_files)} HTML dosyasÄ± bulundu")
        
        html_documents = []
        for html_file in html_files:
            file_path = os.path.join(html_dir, html_file)
            
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # HTML'den baÅŸlÄ±k ve iÃ§erik Ã§Ä±kar
                from bs4 import BeautifulSoup
                soup = BeautifulSoup(content, 'html.parser')
                
                # BaÅŸlÄ±k
                title = soup.find('title')
                title_text = title.get_text().strip() if title else html_file.replace('.html', '')
                
                # Ana baÅŸlÄ±k
                h1 = soup.find('h1')
                main_title = h1.get_text().strip() if h1 else title_text
                
                # Ä°Ã§erik
                content_div = soup.find('div', {'id': 'idcontent'})
                if content_div:
                    content_text = content_div.get_text().strip()
                else:
                    content_text = soup.get_text().strip()
                
                # Ä°Ã§erik temizleme
                content_text = ' '.join(content_text.split())
                content_text = content_text[:2000] + '...' if len(content_text) > 2000 else content_text
                
                # Kategori belirleme
                category = self.determine_category(html_file)
                
                doc = {
                    'id': html_file.replace('.html', ''),
                    'title': title_text,
                    'main_title': main_title,
                    'category': category,
                    'content': content_text,
                    'file': html_file,
                    'url': f'html/{html_file}',
                    'source': 'html_file'
                }
                
                html_documents.append(doc)
                
            except Exception as e:
                print(f"   âŒ {html_file} okunamadÄ±: {e}")
        
        print(f"âœ… {len(html_documents)} HTML dosyasÄ± iÅŸlendi")
        return html_documents
    
    def determine_category(self, filename):
        """Dosya adÄ±ndan kategori belirle"""
        filename_lower = filename.lower()
        
        if 'artes' in filename_lower:
            return 'ARTES - AraÃ§ Tescil'
        elif 'yazi' in filename_lower:
            return 'YAZI SERVÄ°SÄ°'
        elif 'vezne' in filename_lower:
            return 'VEZNE SERVÄ°SÄ°'
        elif 'genelge' in filename_lower:
            return 'GENELGELER'
        elif 'makale' in filename_lower:
            return 'MAKALELER'
        elif 'mevzuat' in filename_lower:
            return 'MEVZUAT'
        elif 'takvim' in filename_lower:
            return 'TAKVÄ°M'
        elif 'hesap' in filename_lower:
            return 'HESAP MAKÄ°NESÄ°'
        elif 'yas' in filename_lower:
            return 'YAÅ HESAPLA'
        elif 'yardim' in filename_lower:
            return 'YARDIM'
        elif 'kaynak' in filename_lower:
            return 'KAYNAK - DESTEK'
        elif 'onoz' in filename_lower:
            return 'Ã–NSÃ–Z'
        elif 'mahkeme' in filename_lower:
            return 'MAHKEME KARARLARI'
        elif 'internet' in filename_lower:
            return 'Ä°NTERNET SÄ°TELERÄ°'
        elif 'tavsiye' in filename_lower:
            return 'TAVSÄ°YELER'
        elif 'tnb' in filename_lower:
            return 'TNB MEVZUATI'
        elif 'noterlik' in filename_lower:
            return 'NOTERLÄ°K KANUNU'
        elif 'isleme' in filename_lower:
            return 'Ä°ÅLEME'
        elif 'islemler' in filename_lower:
            return 'Ä°ÅLEMLER'
        else:
            return 'GENEL'
    
    def merge_json_data(self):
        """JSON dosyalarÄ±ndaki verileri birleÅŸtir"""
        print("ğŸ“Š JSON dosyalarÄ± birleÅŸtiriliyor...")
        
        json_files = [
            ('modern_data_complete.json', 'modern_data'),
            ('complete_analysis.json', 'complete_analysis'),
            ('modern_data.json', 'modern_data_old'),
            ('noter_genelgeleri.json', 'noter_genelgeleri')
        ]
        
        merged_documents = []
        
        for json_file, source_name in json_files:
            if os.path.exists(json_file):
                try:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    self.metadata['data_sources'].append({
                        'file': json_file,
                        'source': source_name,
                        'processed': datetime.now().isoformat()
                    })
                    
                    # DÃ¶kÃ¼manlarÄ± Ã§Ä±kar
                    if 'documents' in data:
                        for doc in data['documents']:
                            if isinstance(doc, dict):
                                doc['source'] = source_name
                                merged_documents.append(doc)
                    
                    # Kategorileri Ã§Ä±kar
                    elif 'categories' in data:
                        for category, items in data['categories'].items():
                            if isinstance(items, list):
                                for item in items:
                                    if isinstance(item, dict):
                                        item['source'] = source_name
                                        merged_documents.append(item)
                    
                    print(f"   âœ… {json_file}: {len(data.get('documents', data.get('categories', {})))} Ã¶ÄŸe iÅŸlendi")
                    
                except Exception as e:
                    print(f"   âŒ {json_file} okunamadÄ±: {e}")
        
        print(f"âœ… {len(merged_documents)} JSON dÃ¶kÃ¼manÄ± birleÅŸtirildi")
        return merged_documents
    
    def create_unified_dataset(self):
        """BirleÅŸik veri seti oluÅŸtur"""
        print("ğŸ”„ BirleÅŸik veri seti oluÅŸturuluyor...")
        
        # 1. Yedek oluÅŸtur
        self.create_backup()
        
        # 2. HTML dosyalarÄ±nÄ± analiz et
        html_documents = self.analyze_html_files()
        
        # 3. JSON verilerini birleÅŸtir
        json_documents = self.merge_json_data()
        
        # 4. TÃ¼m dÃ¶kÃ¼manlarÄ± birleÅŸtir
        all_docs = html_documents + json_documents
        
        # 5. DuplikasyonlarÄ± kaldÄ±r (ID'ye gÃ¶re)
        unique_docs = {}
        for doc in all_docs:
            doc_id = doc.get('id', doc.get('file', '').replace('.html', ''))
            if doc_id and doc_id not in unique_docs:
                unique_docs[doc_id] = doc
            elif doc_id and doc_id in unique_docs:
                # AynÄ± ID'li dÃ¶kÃ¼man varsa, daha gÃ¼ncel olanÄ± al
                if doc.get('source') == 'html_file':
                    unique_docs[doc_id] = doc
        
        # 6. Kategorilere gÃ¶re grupla
        for doc_id, doc in unique_docs.items():
            category = doc.get('category', 'GENEL')
            self.all_categories[category].append(doc)
        
        # 7. Metadata gÃ¼ncelle
        self.metadata['total_documents'] = len(unique_docs)
        self.metadata['total_categories'] = len(self.all_categories)
        
        # 8. Final veri setini oluÅŸtur
        final_data = {
            "metadata": self.metadata,
            "categories": dict(self.all_categories),
            "documents": list(unique_docs.values())
        }
        
        # 9. Dosyaya kaydet
        output_file = "noterlik_complete.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(final_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… BirleÅŸik veri seti oluÅŸturuldu: {output_file}")
        print(f"   ğŸ“Š Toplam dÃ¶kÃ¼man: {len(unique_docs)}")
        print(f"   ğŸ“ Toplam kategori: {len(self.all_categories)}")
        
        return output_file
    
    def validate_data(self, output_file):
        """Veri bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼ doÄŸrula"""
        print("ğŸ” Veri bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ doÄŸrulanÄ±yor...")
        
        try:
            with open(output_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            total_docs = data['metadata']['total_documents']
            total_cats = data['metadata']['total_categories']
            
            # Kategori sayÄ±sÄ±nÄ± kontrol et
            actual_cats = len(data['categories'])
            actual_docs = len(data['documents'])
            
            print(f"   ğŸ“Š Metadata: {total_docs} dÃ¶kÃ¼man, {total_cats} kategori")
            print(f"   ğŸ“Š GerÃ§ek: {actual_docs} dÃ¶kÃ¼man, {actual_cats} kategori")
            
            if total_docs == actual_docs and total_cats == actual_cats:
                print("âœ… Veri bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ doÄŸrulandÄ±!")
                return True
            else:
                print("âŒ Veri bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ hatasÄ±!")
                return False
                
        except Exception as e:
            print(f"âŒ DoÄŸrulama hatasÄ±: {e}")
            return False

def main():
    merger = SafeDataMerger()
    
    # BirleÅŸik veri seti oluÅŸtur
    output_file = merger.create_unified_dataset()
    
    # Veri bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼ doÄŸrula
    if merger.validate_data(output_file):
        print("\nğŸ‰ VERÄ° BÄ°RLEÅTÄ°RME BAÅARILI!")
        print(f"ğŸ“ Yedek klasÃ¶rÃ¼: {merger.backup_dir}")
        print(f"ğŸ“„ Ã‡Ä±ktÄ± dosyasÄ±: {output_file}")
    else:
        print("\nâŒ VERÄ° BÄ°RLEÅTÄ°RME BAÅARISIZ!")
        print(f"ğŸ›¡ï¸ Yedek klasÃ¶rÃ¼nden geri yÃ¼kleyebilirsiniz: {merger.backup_dir}")

if __name__ == "__main__":
    main()
